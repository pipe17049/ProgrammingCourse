# ğŸ–¼ï¸ Pipeline de Procesamiento de ImÃ¡genes Distribuido

**Proyecto de 4 dÃ­as: De Threading a Sistemas Distribuidos con Monitoreo Real** âœ…

Este proyecto evoluciona desde un servidor Django bÃ¡sico hasta un **sistema distribuido de procesamiento de imÃ¡genes** completo con **monitoreo en tiempo real**, demostrando conceptos de concurrencia, paralelismo, arquitecturas distribuidas y mÃ©tricas de producciÃ³n.

## ğŸ¯ Objetivos del Proyecto

### **ğŸ“… DÃA 1: Foundation** 
- âœ… **I/O-bound operations**: Leer archivos grandes del disco
- âœ… **Threading vs Multiprocessing**: ComparaciÃ³n de rendimiento  
- âœ… **Load testing**: MediciÃ³n de concurrencia

### **ğŸ“… DÃA 2: Real Processing**
- âœ… **Filtros reales**: PIL (Pillow) y OpenCV 
- âœ… **CPU-bound tasks**: Blur, sharpen, edge detection, resize
- âœ… **Performance benchmarking**: Sequential vs Threading vs Multiprocessing
- âœ… **Resource monitoring**: CPU, memory, processing time

### **ğŸ“… DÃA 3: Distributed System** 
- âœ… **Sistema distribuido**: Redis + Worker containers
- âœ… **Task distribution**: FIFO queue distribuyendo tareas entre workers especializados
- âœ… **Fault tolerance**: Worker registration, heartbeat, failure handling
- âœ… **Docker orchestration**: docker-compose con mÃºltiples servicios
- âœ… **Monitoring**: Worker status, task tracking, performance metrics

### **ğŸ“… DÃA 4: Smart Monitoring & Metrics** âœ… **COMPLETADO**
- âœ… **Sistema de mÃ©tricas real**: CPU, memoria, utilizaciÃ³n de workers en tiempo real
- âœ… **DetecciÃ³n de carga**: Queue length, busy workers, success rate
- âœ… **Recomendaciones educativas**: CuÃ¡ndo escalar workers (sin ejecuciÃ³n automÃ¡tica)
- âœ… **Dashboard tiempo real**: Terminal UI mostrando mÃ©tricas en vivo
- âœ… **Stress testing funcional**: Scripts para generar carga y ver mÃ©tricas cambiar
- âœ… **Debugging completo**: Resueltos timeouts, mÃ©tricas incorrectas, Docker issues

## ğŸ—ï¸ Arquitectura del Sistema

```
                    ğŸŒ Client
                (curl requests)
                       |
                   ğŸ Django API
                    :8000
                 (Single Instance)
                       |
                ğŸ“¡ Redis Queue
              (Task Distribution
               Worker Registry)
                   /  |  \
                  /   |   \
                 /    |    \
            ğŸ‘· Worker-1  ğŸ‘· Worker-2  ğŸ‘· Worker-3
           I/O Specialist CPU Specialist General Purpose
           resize, blur,   sharpen,      ALL FILTERS
           brightness     edges            |
                |           |              |
                |           |              |
           ğŸ–¼ï¸ Static Images â†â†’ ğŸ’¾ Processed Images
           sample_4k.jpg      static/processed/
           misurina-sunset.jpg
                
    ğŸ“Š Smart Monitoring System (Day 4) âœ…
    â”œâ”€â”€ ğŸ”¥ CPU Usage & ğŸ§  Memory Usage (psutil)
    â”œâ”€â”€ âš¡ Busy Workers & ğŸ“ˆ Worker Utilization  
    â”œâ”€â”€ ğŸ“‹ Queue Length & âœ… Success Rate
    â”œâ”€â”€ ğŸ¬ Scaling Recommendations (Educational)
    â”œâ”€â”€ ğŸ“Š Real-time Terminal Dashboard
    â””â”€â”€ ğŸš€ Stress Testing Scripts (5 tipos)
```

### **ğŸ”„ Flujo de Procesamiento:**

```
1. ğŸ“¤ Client: POST /api/process-batch/distributed/
                    â†“
2. ğŸ Django API: Crea task_id Ãºnico y encola en Redis (LPUSH)
                    â†“
3. ğŸ“¡ Redis Queue: [task1, task2, task3] â†’ Workers pull (BRPOP)
                    â†“
4. ğŸ‘· Worker: Toma prÃ³ximo task disponible (FIFO)
                    â†“
5. ğŸ” Worker: Revisa capabilities DESPUÃ‰S de tomar task
                    â†“
6a. âœ… Compatible: Procesa filtros â†’ Guarda en static/processed/
6b. âŒ Incompatible: Marca task como FAILED (ğŸ’€ Tarea perdida)
                    â†“
7. ğŸ“Š Client: Consulta status con /api/task/{task_id}/status/
```

## ğŸš€ Setup y EjecuciÃ³n

### **OpciÃ³n A: Setup Local (DÃ­as 1-2)**

```bash
# 1. Instalar dependencias
pip install -r requirements.txt

# 2. Crear directorios necesarios
mkdir -p static/processed

# 3. Ejecutar servidor local
python manage.py runserver 8000
```

### **OpciÃ³n B: Setup Distribuido con Docker (DÃ­a 3)**

```bash
# 1. Construir imÃ¡genes
docker-compose build

# 2. Levantar sistema completo
docker-compose up -d

# 3. Verificar servicios
docker-compose ps
```

### **Verificar instalaciÃ³n:**
```bash
# Health check
curl http://localhost:8000/api/health/

# Ver workers activos (solo Docker)
curl http://localhost:8000/api/workers/status/
```

## âš¡ **DEMO RÃPIDO: Ver MÃ©tricas Cambiar** 

**ğŸ¯ Para ver el sistema funcionando inmediatamente:**

```bash
# Terminal 1: Ver mÃ©tricas limpias
python simple_monitoring/cli.py metrics
# âš¡ Busy Workers: 0    ğŸ“ˆ Utilization: 0.0%

# Terminal 2: Lanzar stress test  
python burst_stress.py 50

# Terminal 1: Ver mÃ©tricas cambiar INMEDIATAMENTE
python simple_monitoring/cli.py metrics  
# âš¡ Busy Workers: 3    ğŸ“ˆ Utilization: 100.0%
# ğŸ¬ Action: MAINTAIN   ğŸ“ Reason: System at optimal capacity
```

**ğŸ”¥ Resultado**: En **< 5 segundos** verÃ¡s workers pasar de 0% a 100% utilizaciÃ³n con recomendaciones inteligentes.

## ğŸ§ª Testing y Comandos

### **ğŸ“… DÃA 1: Endpoints BÃ¡sicos**

```bash
# Health check
curl http://localhost:8000/api/health/

# InformaciÃ³n de imagen (rÃ¡pido)
curl http://localhost:8000/api/image/info/

# Descargar imagen 4K (I/O-bound)  
curl http://localhost:8000/api/image/4k/ -o downloaded_4k.jpg

# Imagen con procesamiento lento
curl "http://localhost:8000/api/image/slow/?delay=3.0" -o slow_4k.jpg

# EstadÃ­sticas del servidor
curl http://localhost:8000/api/stats/
```

### **ğŸ“… DÃA 2: Filtros Reales (PIL/OpenCV)**

```bash
# Procesamiento con filtros secuencial
curl -X POST http://localhost:8000/api/process-batch/sequential/ \
  -H "Content-Type: application/json" \
  -d '{"filters": ["resize", "blur"], "filter_params": {"resize": {"width": 800, "height": 600}, "blur": {"radius": 3.0}}}'

# Procesamiento con threading
curl -X POST http://localhost:8000/api/process-batch/threading/ \
  -H "Content-Type: application/json" \
  -d '{"filters": ["sharpen", "edges"]}'

# Procesamiento con multiprocessing
curl -X POST http://localhost:8000/api/process-batch/multiprocessing/ \
  -H "Content-Type: application/json" \
  -d '{"filters": ["brightness"], "filter_params": {"brightness": {"factor": 1.5}}}'

# Comparar todos los mÃ©todos
curl -X POST http://localhost:8000/api/process-batch/compare-all/ \
  -H "Content-Type: application/json" \
  -d '{"filters": ["resize", "blur"]}'

# Stress test
curl -X POST http://localhost:8000/api/process-batch/stress/ \
  -H "Content-Type: application/json" \
  -d '{"filters": ["sharpen", "edges"], "num_iterations": 5}'
```

### **ğŸ“… DÃA 3: Sistema Distribuido (Docker)**

```bash
# Procesamiento distribuido
curl -X POST http://localhost:8000/api/process-batch/distributed/ \
  -H "Content-Type: application/json" \
  -d '{"filters": ["resize", "sharpen", "edges"], "filter_params": {"resize": {"width": 1024, "height": 768}}}'

# Estado de workers
curl http://localhost:8000/api/workers/status/ | python -m json.tool

# Monitoreo en tiempo real
watch -n 2 'curl -s http://localhost:8000/api/workers/status/ | python -m json.tool'

# Consultar estado de task individual (usar task_id de la respuesta anterior)
curl http://localhost:8000/api/task/{TASK_ID}/status/ | python -m json.tool
```

### **ğŸ¯ Testing Worker Specialization**

```bash
# Test: Solo worker-2 puede hacer 'sharpen'
# 1. Parar worker-3: docker-compose stop worker-3
# 2. Enviar mÃºltiples tareas sharpen:
for i in {1..5}; do
  curl -X POST http://localhost:8000/api/process-batch/distributed/ \
    -H "Content-Type: application/json" \
    -d '{"filters": ["sharpen"]}' &
done

# 3. Ver resultados: worker-1 falla, worker-2 procesa
curl http://localhost:8000/api/workers/status/
```

### **ğŸ” Testing Job Failure vs Worker Failure**

```bash
# SCENARIO 1: Job Failure (Worker incompatible)
# 1. Enviar task que worker-1 no puede manejar
curl -X POST http://localhost:8000/api/process-batch/distributed/ \
  -H "Content-Type: application/json" \
  -d '{"filters": ["sharpen"]}' \
  | jq '.task_id' # Guardar task_id

# 2. Consultar status especÃ­fico del job
curl http://localhost:8000/api/task/{TASK_ID}/status/ | jq '
{
  status: .status,
  failure_type: .failure_type,
  failure_reason: .failure_reason,
  explanation: .explanation,
  error: .error
}'

# RESPUESTA de Job Failure:
# {
#   "status": "failed",
#   "failure_type": "job_failure",
#   "failure_reason": "worker_capability_mismatch", 
#   "explanation": "Worker tomÃ³ task pero no puede manejar el filtro requerido",
#   "error": "Worker worker-1 cannot handle filters: ['sharpen']"
# }

# SCENARIO 2: Worker Failure (Worker caÃ­do)
# 1. Parar todos los workers
docker-compose stop worker-1 worker-2 worker-3

# 2. Enviar task
curl -X POST http://localhost:8000/api/process-batch/distributed/ \
  -H "Content-Type: application/json" \
  -d '{"filters": ["resize"]}' \
  | jq '.task_id'

# 3. Consultar despuÃ©s de timeout
curl http://localhost:8000/api/task/{TASK_ID}/status/ | jq '
{
  status: .status,
  explanation: "No workers available to process task"
}'

# RESPUESTA de Worker Failure:
# {
#   "status": "pending",  # Task nunca fue tomada
#   "explanation": "No workers available to process task"
# }
```

## ğŸ“Š Endpoints Disponibles

### **DÃA 1: BÃ¡sicos**
| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/api/health/` | GET | Health check del servidor |
| `/api/image/info/` | GET | Metadata de imagen sin transferir |
| `/api/image/4k/` | GET | Descargar imagen 4K (I/O-bound) |
| `/api/image/slow/?delay=N` | GET | Imagen con delay simulado |
| `/api/stats/` | GET | EstadÃ­sticas del servidor |

### **DÃA 2: Procesamiento Real**
| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/api/process-batch/sequential/` | POST | Procesamiento secuencial con filtros |
| `/api/process-batch/threading/` | POST | Procesamiento con threading |
| `/api/process-batch/multiprocessing/` | POST | Procesamiento con multiprocessing |
| `/api/process-batch/compare/` | POST | Comparar threading vs multiprocessing |
| `/api/process-batch/compare-all/` | POST | Comparar todos los mÃ©todos |
| `/api/process-batch/stress/` | POST | Test de estrÃ©s con mÃºltiples iteraciones |

### **DÃA 3: Sistema Distribuido**
| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/api/process-batch/distributed/` | POST | Procesamiento distribuido con workers |
| `/api/workers/status/` | GET | Estado de todos los workers |
| `/api/task/<task_id>/status/` | GET | **Estado de task individual** (job failure vs worker failure) |

### **DÃA 4: Sistema de Monitoreo** âœ…
| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/api/metrics/` | GET | **MÃ©tricas del sistema** (CPU, memoria, workers, recomendaciones) |

### **Comandos CLI de Monitoreo:**
| Comando | DescripciÃ³n |
|---------|-------------|
| `python simple_monitoring/cli.py check` | Verificar API disponible |
| `python simple_monitoring/cli.py metrics` | Ver mÃ©tricas actuales |
| `python simple_monitoring/cli.py monitor` | Dashboard en tiempo real |
| `python simple_monitoring/cli.py stress 10` | Stress test via API |

### **Filtros Disponibles:**
- **`resize`**: Cambiar tamaÃ±o (PIL) - I/O-bound
- **`blur`**: Difuminado gaussiano (PIL) - I/O-bound  
- **`brightness`**: Ajuste de brillo (PIL) - I/O-bound
- **`sharpen`**: Nitidez avanzada (OpenCV) - CPU-bound
- **`edges`**: DetecciÃ³n de bordes (OpenCV) - CPU-bound

## ğŸ” AnÃ¡lisis de Rendimiento

### **ğŸƒâ€â™‚ï¸ DÃA 2: Threading vs Multiprocessing**

**Para filtros I/O-bound (resize, blur, brightness):**
- âœ… **Threading wins**: ~3-5x mÃ¡s rÃ¡pido que secuencial
- âš¡ **Multiprocessing**: ~2-3x mÃ¡s rÃ¡pido (overhead de procesos)
- ğŸ§  **RazÃ³n**: GIL se libera durante I/O, threading es mÃ¡s eficiente

**Para filtros CPU-bound (sharpen, edges):**
- âœ… **Multiprocessing wins**: ~4-6x mÃ¡s rÃ¡pido que secuencial  
- ğŸŒ **Threading**: ~1.2x mÃ¡s rÃ¡pido (limitado por GIL)
- ğŸ§  **RazÃ³n**: CPU-bound necesita verdadero paralelismo

### **ğŸŒ DÃA 3: Sistema Distribuido**

**CaracterÃ­sticas del FIFO Queue:**
- âš–ï¸ **Load Balancing**: Simple FIFO, no inteligente
- âŒ **Fault Tolerance**: Tareas fallan si worker incompatible las toma
- ğŸ¯ **Worker Specialization**: Configurado por `WORKER_CAPABILITIES`
- ğŸ“Š **Monitoring**: Worker registry con heartbeat

**Worker-3 como "Salvador":**
- ğŸ›¡ï¸ Worker-3 (`capabilities=all`) previene fallos
- ğŸ² DistribuciÃ³n basada en timing, no capabilities
- âš ï¸ Si worker-3 se cae, tareas incompatibles fallan para siempre

## ğŸ“Š **DÃA 4: Sistema de Monitoreo Real** âœ…

### **ğŸ¯ MÃ©tricas en Tiempo Real**

El sistema incluye **monitoreo inteligente** que recopila mÃ©tricas reales del sistema:

```bash
# Ver mÃ©tricas actuales
python simple_monitoring/cli.py metrics

# Resultado example:
ğŸ“Š SYSTEM METRICS
========================================
ğŸ”¥ CPU Usage:          30.5%
ğŸ§  Memory Usage:       69.5%
ğŸ’½ Memory Available:    2.3 GB

âš™ï¸ WORKER METRICS
--------------------
ğŸ‘¥ Active Workers:        3
âš¡ Busy Workers:          3
ğŸ“ˆ Utilization:      100.0%
ğŸ“‹ Queue Length:          0
âœ… Success Rate:      100.0%

ğŸ“ SCALING RECOMMENDATION (Educational)
----------------------------------------
ğŸ“Š Current Workers:       3
ğŸ¯ Recommended:           3
ğŸ¬ Action:           MAINTAIN
ğŸ“ Reason:           System operating within optimal parameters
ğŸ¯ Confidence:        80.0%
âš¡ Urgency:          NONE
```

### **ğŸš€ Stress Testing Scripts**

**5 tipos de stress tests** para generar carga y observar mÃ©tricas:

```bash
# 1. SIMPLE STRESS - Controlado
python simple_stress.py 5        # 5 tareas secuenciales

# 2. BURST STRESS - Explosivo  
python burst_stress.py 50        # 50 tareas concurrentes

# 3. CONTINUOUS STRESS - Sostenido
python continuous_stress.py 60   # 5 tareas/seg por 60 segundos

# 4. SUSTAINED STRESS - Prolongado
python sustained_stress.py       # Mantiene cola llena

# 5. DISTRIBUTED STRESS - EspecÃ­fico
python distributed_stress.py 20  # 20 tareas distribuidas
```

### **ğŸ“ˆ Ver MÃ©tricas Cambiar en Tiempo Real**

```bash
# Terminal 1: Lanzar stress test
python burst_stress.py 50

# Terminal 2: Ver mÃ©tricas cambiar inmediatamente  
python simple_monitoring/cli.py metrics

# Antes del stress:
âš¡ Busy Workers: 0    ğŸ“ˆ Utilization: 0.0%

# Durante el stress:
âš¡ Busy Workers: 3    ğŸ“ˆ Utilization: 100.0%
ğŸ¬ Action: MAINTAIN   ğŸ“ Reason: System at optimal capacity
```

### **ğŸ›ï¸ Dashboard en Tiempo Real**

```bash
# Terminal interactivo con mÃ©tricas en vivo
python simple_monitoring/cli.py monitor

# Actualiza mÃ©tricas cada 2 segundos mostrando:
# - CPU/Memory usage en tiempo real
# - Worker utilization dinÃ¡mica  
# - Recomendaciones que cambian con la carga
# - Success rate y estadÃ­sticas
```

## ğŸ› ï¸ Troubleshooting

### **Local Setup Issues**
```bash
# Dependencias faltantes
pip install -r requirements.txt

# Directorios faltantes  
mkdir -p static/processed static/images

# Puerto en uso
python manage.py runserver 8080
```

### **Docker Issues**
```bash
# Servicios no inician
docker-compose down && docker-compose up --build

# Redis connection failed
docker-compose logs redis

# Workers no registran
docker-compose logs worker-1
```

### **Workers No Processan**
```bash
# Verificar workers activos
curl http://localhost:8000/api/workers/status/

# Verificar cola Redis
docker-compose exec redis redis-cli LLEN task_queue

# Restart workers
docker-compose restart worker-1 worker-2 worker-3
```

### **ğŸ“Š Problemas de Monitoreo (Resueltos)** âœ…

```bash
# PROBLEMA: MÃ©tricas muestran "Busy Workers: 0" durante alta carga
# CAUSA: API container usando cÃ³digo viejo
# SOLUCIÃ“N: Rebuild agresivo del container
docker-compose stop api && docker-compose rm -f api
docker rmi projects-api
docker-compose build api --no-cache && docker-compose up -d api

# PROBLEMA: API timeouts durante stress tests  
# CAUSA: API esperando sincrÃ³nicamente tareas distribuidas
# SOLUCIÃ“N: Endpoint distribuido retorna task_id inmediatamente

# PROBLEMA: MÃ©tricas incorrectas en Redis
# CAUSA: Datos viejos acumulados de tests anteriores
# SOLUCIÃ“N: Purgar Redis entre tests
docker exec image_processing_redis redis-cli FLUSHALL

# VERIFICAR: MÃ©tricas funcionando correctamente
python simple_monitoring/cli.py metrics
# Debe mostrar busy workers > 0 durante carga alta
```

## ğŸ† Logros del Proyecto

### **ğŸ“ˆ ProgresiÃ³n TÃ©cnica:**
1. **DÃ­a 1**: Servidor bÃ¡sico I/O-bound â†’ Threading fundamentals
2. **DÃ­a 2**: Filtros reales PIL/OpenCV â†’ CPU vs I/O bound analysis  
3. **DÃ­a 3**: Sistema distribuido â†’ Redis, Docker, Load balancing
4. **DÃ­a 4**: **Sistema de monitoreo completo** â†’ MÃ©tricas reales, stress testing, debugging

### **ğŸ¯ Conceptos Demostrados:**
- âœ… **GIL Impact**: Threading vs Multiprocessing en diferentes workloads
- âœ… **Real-world Libraries**: PIL, OpenCV, Redis en production
- âœ… **Distributed Architectures**: Message queues, worker pools, fault tolerance
- âœ… **DevOps Integration**: Docker, docker-compose, multi-service systems
- âœ… **Performance Analysis**: Benchmarking, monitoring, bottleneck identification
- âœ… **Real-time Monitoring**: CPU/Memory tracking, worker utilization metrics
- âœ… **Stress Testing**: 5 tipos de scripts para generar carga controlada
- âœ… **Production Debugging**: Resolver timeouts, mÃ©tricas incorrectas, Docker issues

### **ğŸš€ Logros Ãšnicos de este Proyecto:**
- ğŸ¯ **MÃ©tricas que cambian en tiempo real** - Ver utilizaciÃ³n de workers subir de 0% a 100%
- ğŸ”„ **Debugging sistemÃ¡tico** - Resolver problemas reales de desarrollo distribuido
- ğŸ“Š **Monitoreo educativo** - Recomendaciones de scaling sin ejecuciÃ³n automÃ¡tica  
- âš¡ **Stress testing cientÃ­fico** - Scripts controlados para generar cargas especÃ­ficas
- ğŸ³ **Docker debugging avanzado** - Resolver containers usando cÃ³digo viejo
- ğŸ“ˆ **Performance real** - 300+ tareas procesadas, workers al 100% utilizaciÃ³n

---

**ğŸš€ De conceptos bÃ¡sicos de concurrencia a sistemas distribuidos con monitoreo real en 4 dÃ­as!**

## ğŸ–¥ï¸ **SETUP PARA WINDOWS**

### **InstalaciÃ³n rÃ¡pida:**
```cmd
# 1. Ir a Projects folder
cd ProgrammingCourse\Chapter-Threads\Projects

# 2. Crear entorno virtual
python -m venv venv
venv\Scripts\activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Crear directorio
mkdir static\processed

# 5. Verificar
python manage.py check

# 6. Iniciar servidor
python manage.py runserver 8000
```

### **Probar filtros nuevos:**
```cmd
curl -X POST http://localhost:8000/api/process-batch/threading/ -H "Content-Type: application/json" -d "{\"filters\": [\"resize\", \"blur\"], \"filter_params\": {\"resize\": {\"width\": 800, \"height\": 600}, \"blur\": {\"radius\": 3.0}}}"
```

**Nuevos endpoints:**
- `/api/process-batch/sequential/` - Procesamiento secuencial
- `/api/process-batch/threading/` - Con threading  
- `/api/process-batch/multiprocessing/` - Con multiprocessing
- `/api/process-batch/compare-all/` - Comparar todos los mÃ©todos
